<html lang="ko">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <meta name="author" content="Mark Otto, Jacob Thornton, and Bootstrap contributors">
  <meta name="generator" content="Hugo 0.80.0">
  <title>Opencv.js 안면 인식</title>

  <link rel="canonical" href="https://getbootstrap.com/docs/5.0/examples/album/">



  <!-- Bootstrap core CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">

  <style>
    .bd-placeholder-img {
      font-size: 1.125rem;
      text-anchor: middle;
      -webkit-user-select: none;
      -moz-user-select: none;
      user-select: none;
    }

    @media (min-width: 768px) {
      .bd-placeholder-img-lg {
        font-size: 3.5rem;
      }
    }
    @font-face {
      font-family: 'IAMAPLAYER';
      src: url('https://cdn.jsdelivr.net/gh/projectnoonnu/noonfonts_2307-2@1.0/IAMAPLAYER.woff2') format('woff2');
      font-weight: normal;
      font-style: normal;
    }
    #outputCanvas {
      font-family: 'IAMAPLAYER', sans-serif; /* 한국어 폰트 적용 */
    }

    #voiceForm {
      margin:10px;
    }

    #record_btn{
      margin:10px;  
    }
  </style>


</head>

<body>
  <header>
    <div class="collapse bg-dark" id="navbarHeader">
      <div class="container">
        <div class="row">
          <div class="col-sm-8 col-md-7 py-4">
            <h4 class="text-white">몰입형 기말고사</h4>
            <p class="text-muted">객체 인식 보안 프로젝트
            </p>
          </div>
        </div>
      </div>
    </div>
    <div class="navbar navbar-dark bg-dark shadow-sm">
      <div class="container">
        <a href="#" class="navbar-brand d-flex align-items-center">
          <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" stroke="currentColor"
            stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true" class="me-2"
            viewBox="0 0 24 24">
            <path d="M23 19a2 2 0 0 1-2 2H3a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h4l2-3h6l2 3h4a2 2 0 0 1 2 2z" />
            <circle cx="12" cy="13" r="4" />
          </svg>
          <strong>Opencv.js</strong>
        </a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarHeader"
          aria-controls="navbarHeader" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
      </div>
    </div>
  </header>

  <main>
    <section class="py-5 text-center container">
      <div class="row py-lg-5">
        <div class="col-lg-6 col-md-8 mx-auto">
          <h1 class="fw-light">얼굴, 음성 인식 보안</h1>
          <p class="lead text-muted" id="status">OpenCV.js is loading...</p>
          <div class="spinner-border text-primary" role="status" id="loader">
            <span class="sr-only"></span>
          </div>
        </div>
      </div>
    </section>

    <div class="album py-5 bg-light">
      <div class="container">
        <div class="row row-cols-1 g-3 text-center">
          <div class="col">
            <div class="card shadow-sm">
              <canvas id="output" width=640 height=480 style="max-width: 100%"></canvas>
              <div class="card-body">
                <div class='py-2'>
                  <table>
                    <tr id="targetImgs"></tr>
                    <tr id="targetNames"></tr>
                  </table>
                </div>
                <div class='py-2'>
                  <button id="addPersonButton" type="button" disabled="true" class="btn btn-sm btn-outline-secondary">사람
                    추가</button>
                  <button id="removePersonButton" type="button" disabled="true" class="btn btn-sm btn-outline-secondary">저장된 사람 정리</button>
                  <article class="form" id="voiceForm">
                    <input type="text" id="key" placeholder="여기에 비밀번호 입력"/>
                    <input type="hidden" id="search_console" />
                    <div id='record_btn' class="record_btn">
                      <button type="button" onclick="endRecord()" class="btn btn-sm btn-outline-secondary">녹음중단</button>
                    </div>
                  </article>
                  <button id="unlockBtn" type="button" onclick="unlock()" class="btn btn-sm btn-outline-secondary">잠금해제</button>
                </div>
                <div class="alert alert-success" role="alert" style="display: none;">
                  잠금이 해제되었습니다
                </div>
                <div class="alert alert-danger" role="alert" style="display: none;">
                  잘못된 입력입니다. 다시 시도해주세요.
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

  </main>

  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4" crossorigin="anonymous"></script>

  <script type='text/javascript'>
    var hostName;
    var netDet = undefined, netRecogn = undefined;
    var persons = {};
    
    //! [Run face detection model]
    function detectFaces(img) {
      var blob = cv.blobFromImage(img, 1, { width: 192, height: 144 }, [104, 117, 123, 0], false, false);
      netDet.setInput(blob);
      var out = netDet.forward();

      var faces = [];
      for (var i = 0, n = out.data32F.length; i < n; i += 7) {
        var confidence = out.data32F[i + 2];
        var left = out.data32F[i + 3] * img.cols;
        var top = out.data32F[i + 4] * img.rows;
        var right = out.data32F[i + 5] * img.cols;
        var bottom = out.data32F[i + 6] * img.rows;
        left = Math.min(Math.max(0, left), img.cols - 1);
        right = Math.min(Math.max(0, right), img.cols - 1);
        bottom = Math.min(Math.max(0, bottom), img.rows - 1);
        top = Math.min(Math.max(0, top), img.rows - 1);

        if (confidence > 0.5 && left < right && top < bottom) {
          faces.push({ x: left, y: top, width: right - left, height: bottom - top })
        }
      }
      blob.delete();
      out.delete();
      return faces;
    };
    //! [Run face detection model]

    //! [Get 128 floating points feature vector]
    function face2vec(face) {
      var blob = cv.blobFromImage(face, 1.0 / 255, { width: 96, height: 96 }, [0, 0, 0, 0], true, false)
      netRecogn.setInput(blob);
      var vec = netRecogn.forward();
      blob.delete();
      return vec;
    };
    //! [Get 128 floating points feature vector]

    //! [Recognize]
      function recognize(face) {
      var vec = face2vec(face);
      var bestMatchName = 'unknown';
      var bestMatchScore = 0.5;  // Actually, the minimum is -1 but we use it as a threshold.
      for (name in persons) {
        var personVec = persons[name];
        var score = vec.dot(personVec);
        if (score > bestMatchScore) {
          bestMatchScore = score;
          bestMatchName = name;
        }
      }
      vec.delete();
      hostName = bestMatchName;
      return bestMatchName;
    };
    //! [Recognize]

    function loadModels(callback) {
      var utils = new Utils('');
      var proto = 'https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy_lowres.prototxt';
      var weights = 'https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20180205_fp16/res10_300x300_ssd_iter_140000_fp16.caffemodel';
      var recognModel = 'https://raw.githubusercontent.com/pyannote/pyannote-data/master/openface.nn4.small2.v1.t7';
      utils.createFileFromUrl('face_detector.prototxt', proto, () => {
        document.getElementById('status').innerHTML = 'Downloading face_detector.caffemodel';
        utils.createFileFromUrl('face_detector.caffemodel', weights, () => {
          document.getElementById('status').innerHTML = 'Downloading OpenFace model';
          utils.createFileFromUrl('face_recognition.t7', recognModel, () => {
            document.getElementById('status').innerHTML = '';
            netDet = cv.readNetFromCaffe('face_detector.prototxt', 'face_detector.caffemodel');
            netRecogn = cv.readNetFromTorch('face_recognition.t7');
            callback();
          });
        });
      });
    };

    function main() {
      // Create a camera object.
      var output = document.getElementById('output');
      var camera = document.createElement("video");
      camera.setAttribute("width", output.width);
      camera.setAttribute("height", output.height);

      // Get a permission from user to use a camera.
      navigator.mediaDevices.getUserMedia({ video: true, audio: false })
        .then(function (stream) {
          camera.srcObject = stream;
          camera.onloadedmetadata = function (e) {
            camera.play();
          };
        });

      //! [Open a camera stream]
      var cap = new cv.VideoCapture(camera);
      var frame = new cv.Mat(camera.height, camera.width, cv.CV_8UC4);
      var frameBGR = new cv.Mat(camera.height, camera.width, cv.CV_8UC3);
      //! [Open a camera stream]

      //! [Add a person]
      document.getElementById('addPersonButton').onclick = function () {
        var rects = detectFaces(frameBGR);
        if (rects.length > 0) {
          var face = frameBGR.roi(rects[0]);
      
          var name = prompt('이름을 알려주세요:');
          
          // Check if the name is null or empty before proceeding
          if (name !== null && name.trim() !== '') {
            var cell = document.getElementById("targetNames").insertCell(0);
            cell.innerHTML = name;
      
            persons[name] = face2vec(face).clone();
      
            var canvas = document.createElement("canvas");
            canvas.setAttribute("width", 96);
            canvas.setAttribute("height", 96);
            var cell = document.getElementById("targetImgs").insertCell(0);
            cell.appendChild(canvas);
      
            var faceResized = new cv.Mat(canvas.height, canvas.width, cv.CV_8UC3);
            cv.resize(face, faceResized, { width: canvas.width, height: canvas.height });
            cv.cvtColor(faceResized, faceResized, cv.COLOR_BGR2RGB);
            cv.imshow(canvas, faceResized);
            faceResized.delete();
          } else {
            alert('이름을 입력해주세요.');
          }
        }
        // 사람을 추가한 후 "사람 제거" 버튼을 활성화합니다.
        document.getElementById('removePersonButton').disabled = false;
      };
      //! [Add a person]

      //! [remove a person]
      document.getElementById('removePersonButton').onclick = function () {
        var nameToRemove = prompt('제거할 사람의 이름을 입력하세요:');
        var cellIndexToRemove = -1;
      
        if (nameToRemove) {
          // persons 객체에서 해당하는 사람을 제거합니다.
          if (persons.hasOwnProperty(nameToRemove)) {
            delete persons[nameToRemove];
      
            // targetNames 행과 targetImgs 행을 가져옵니다.
            var targetNamesRow = document.getElementById('targetNames');
            var targetImgsRow = document.getElementById('targetImgs');
      
            // 행이 존재하는지 확인합니다.
            if (targetNamesRow && targetImgsRow) {
              for (var i = 0; i < targetNamesRow.cells.length; i++) {
                if (targetNamesRow.cells[i].innerText === nameToRemove) {
                  cellIndexToRemove = i;
                  break;
                }
              }
      
              if (cellIndexToRemove !== -1) {
                // targetNames 행에서 사람을 제거합니다.
                targetNamesRow.deleteCell(cellIndexToRemove);
      
                // targetImgs 행에서 해당하는 캔버스를 제거합니다.
                targetImgsRow.deleteCell(cellIndexToRemove);
      
                // After removing the cells, we also need to update the length of targetNamesRow and targetImgsRow
                // since they will be reduced by 1 after the cell removal.
                targetNamesRow.cells.length--;
                targetImgsRow.cells.length--;
              }
            } else {
              console.error("targetNames or targetImgs row not found.");
            }
          } else {
            alert('해당하는 이름의 사람을 찾을 수 없습니다.');
          }
        }
      };      
      //! [remove a person]

      const FPS = 12; 
      function captureFrame() {
        var begin = Date.now();
        cap.read(frame); 
        cv.cvtColor(frame, frameBGR, cv.COLOR_RGBA2BGR);

        var faces = detectFaces(frameBGR);
        faces.forEach(function (rect) {
          cv.rectangle(frame, { x: rect.x, y: rect.y }, { x: rect.x + rect.width, y: rect.y + rect.height }, [0, 255, 0, 255]);

          var face = frameBGR.roi(rect);
          var name = recognize(face);
          cv.putText(frame, name, { x: rect.x, y: rect.y }, cv.FONT_HERSHEY_SIMPLEX, 1.0, [0, 255, 0, 255], 2, cv.LINE_AA, false);
        });

        cv.imshow(output, frame);

        var delay = 1000 / FPS - (Date.now() - begin);
        setTimeout(captureFrame, delay);

      };

      loadModels(function () {
        captureFrame();
        document.getElementById('addPersonButton').disabled = false;
        console.log('captureFrame')
      });

    };

    function onOpenCvReady() {
      cv['onRuntimeInitialized'] = () => {
        main();

        document.getElementById('loader').style.display = "none";
      }
    }

    const searchConsole = document.getElementById("search_console");
    const key = document.getElementById("key");

    // ----- 현재 브라우저에서 API 사용이 유효한가를 검증
    function availabilityFunc() {
      //현재 SpeechRecognition을 지원하는 크롬 버전과 webkit 형태로 제공되는 버전이 있으므로 둘 중 해당하는 생성자를 호출한다.
      recognition = new webkitSpeechRecognition() || new SpeechRecognition();
      recognition.lang = "ko"; // 음성인식에 사용되고 반환될 언어를 설정한다.
      recognition.maxAlternatives = 5; //음성 인식결과를 5개 까지 보여준다.

      if (!recognition) {
        alert("현재 브라우저는 사용이 불가능합니다.");
      }
    }

    // --- 음성녹음을 실행하는 함수
    function startRecord() {
      console.log("시작");

      //음성인식 결과를 반환
      // SpeechRecognitionResult 에 담겨서 반환된다.
      recognition.addEventListener("result", (e) => {
        var a = 0;
        searchConsole.value = e.results[0][0].transcript;
        searchConsole.value = searchConsole.value.replace(/(\s*)/g, "");
        key.value = key.value.replace(/(\s*)/g, "");
        //모르는 사람이 아닐 경우에만 체크
        if(hostName != 'unkown'){
          if(searchConsole.value == key.value){
            console.log('성공');
            a = 1;
            var alertSuccess = document.querySelector('.alert-success');
            alertSuccess.style.display = 'block';

            // 일정 시간 후에 알림을 숨기도록 설정
            setTimeout(function() {
              alertSuccess.style.display = 'none';
            }, 2000); // 2초 후에 알림이 사라짐.
          }
        }
        if(a == 0){
          console.log('실패');
          var alertDanger = document.querySelector('.alert-danger');
          alertDanger.style.display = 'block';

          // 일정 시간 후에 알림을 숨기도록 설정
          setTimeout(function() {
            alertDanger.style.display = 'none';
          }, 2000); // 2초 후에 알림이 사라짐.
          console.log(searchConsole.value);
        }
        
      });

      recognition.start();
    }
    //  녹음중단 클릭 시 종료(안 눌러도 음성인식은 알아서 종료됨)
    function endRecord() {
      console.log("종료");
      recognition.stop(); // 음성인식을 중단하고 중단까지의 결과를 반환
    }

    window.addEventListener("load", availabilityFunc);

    //잠금해제 기능
    function unlock(){
      console.log(hostName);
      startRecord();
    }
    //잠금해제 기능
  </script>

  <script src="utils.js" type="text/javascript"></script>
  <script async src="opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>

</body>

</html>